# robots.txt for ProURLMonitor
# This file tells search engines which pages to crawl and which to skip

User-agent: *
Allow: /

# Disallow admin and API routes
Disallow: /api/
Disallow: /admin/
Disallow: /_next/
Disallow: /login
Disallow: /signup

# Allow specific tools
Allow: /tools/
Allow: /app/

# Crawl delay (be nice to our servers)
Crawl-delay: 1

# Sitemap location
Sitemap: https://www.prourlmonitor.com/api/sitemap.xml
